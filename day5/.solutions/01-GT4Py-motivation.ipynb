{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Why GT4Py?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example 1: A simple point-wise stencil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compare a NumPy, CuPy and GT4Py implementation of the point-wise stencil\n",
    "```\n",
    "d[i, j, k] = a[i, j, k] + b[i, j, k] - c[i, j, k]\n",
    "```\n",
    "Timings are measured using the `%timeit` magic command. This command times a single statement or function call by averaging over multiple runs. It has the additional advantage of synchronizing the CPU and the GPU at the end of each run, thus making the output reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.cupy/kernel_cache\n",
    "!rm -rf .gt4py_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the size of the computational domain. We'll be using a large domain in order to hide overhead as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (512, 512, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.2 ms ± 227 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f_numpy(a, b, c, d):\n",
    "    d[...] = a + b - c\n",
    "    \n",
    "a = np.random.rand(*shape)\n",
    "b = np.random.rand(*shape)\n",
    "c = np.random.rand(*shape)\n",
    "d = np.empty_like(a)\n",
    "\n",
    "f_numpy(a, b, c, d)\n",
    "\n",
    "%timeit f_numpy(a, b, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644 μs ± 122 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def f_cupy(a, b, c, d):\n",
    "    d[...] = a + b - c\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "    \n",
    "a = cp.asarray(np.random.rand(*shape))\n",
    "b = cp.asarray(np.random.rand(*shape))\n",
    "c = cp.asarray(np.random.rand(*shape))\n",
    "d = cp.empty_like(a)\n",
    "\n",
    "f_cupy(a, b, c, d)\n",
    "\n",
    "%timeit f_cupy(a, b, c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GT4Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479 μs ± 317 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gt4py.next as gtx\n",
    "\n",
    "#backend = None             # Embedded, native Python execution\n",
    "#backend = gtx.gtfn_cpu     # Translated to C code\n",
    "backend = gtx.gtfn_gpu     # Translated to GPU (CUDA or HIP) code\n",
    "\n",
    "I = gtx.Dimension(\"I\")\n",
    "J = gtx.Dimension(\"J\")\n",
    "K = gtx.Dimension(\"K\")\n",
    "\n",
    "field_domain = gtx.domain({\n",
    "    I: (0, shape[0]),\n",
    "    J: (0, shape[1]),\n",
    "    K: (0, shape[2]),\n",
    "})\n",
    "\n",
    "IJKField = gtx.Field[gtx.Dims[I, J, K], gtx.float64]\n",
    "\n",
    "@gtx.field_operator\n",
    "def f_gt4py(a: IJKField, b: IJKField, c: IJKField) -> IJKField:\n",
    "    return a + b - c\n",
    "\n",
    "@gtx.program\n",
    "def f_gt4py_program(a: IJKField, b: IJKField, c: IJKField,\n",
    "    nx: gtx.int32, ny: gtx.int32, nz: gtx.int32, out: IJKField):\n",
    "    f_gt4py(a=a, b=b, c=c, out=out,\n",
    "        domain={I: (0, nx), J: (0, ny), K: (0, nz)}\n",
    "    )\n",
    "        \n",
    "a = gtx.as_field(field_domain, np.random.rand(*field_domain.shape), allocator=backend)\n",
    "b = gtx.as_field(field_domain, np.random.rand(*field_domain.shape), allocator=backend)\n",
    "c = gtx.as_field(field_domain, np.random.rand(*field_domain.shape), allocator=backend)\n",
    "d = gtx.zeros(field_domain, dtype=gtx.float64, allocator=backend)\n",
    "\n",
    "f_gt4py_stencil = f_gt4py_program.with_backend(backend)\n",
    "\n",
    "compute_domain = field_domain\n",
    "\n",
    "def run():\n",
    "    f_gt4py_stencil(a=a, b=b, c=c, nx=shape[0], ny=shape[1], nz=shape[2], out=d)\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "\n",
    "run()\n",
    "\n",
    "%timeit run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example 2: Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example compares a NumPy, CuPy and GT4Py implementation of the Laplacian stencil that we saw before in our stencil2d code that we have been working with:\n",
    "```\n",
    "lap[i, j, k] = - 4 * phi[  i,   j, k] \n",
    "               +     phi[i-1,   j, k] \n",
    "               +     phi[i+1,   j, k] \n",
    "               +     phi[  i, j-1, k] \n",
    "               +     phi[  i, j+1, k]\n",
    "```\n",
    "Timings are measured using the `%timeit` magic command. This command times a single statement or function call by averaging over multiple runs. It has the additional advantage of synchronizing the CPU and the GPU at the end of each run, thus making the output reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_with_halo = (shape[0] + 2, shape[1] + 2, shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 ms ± 314 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def lap_numpy(phi, lap):\n",
    "    lap[1:-1, 1:-1] = (\n",
    "        - 4. * phi[1:-1, 1:-1]\n",
    "        +      phi[ :-2, 1:-1]\n",
    "        +      phi[  2:, 1:-1]\n",
    "        +      phi[1:-1,  :-2]\n",
    "        +      phi[1:-1,   2:]\n",
    "    )\n",
    "    \n",
    "phi = np.random.rand(*shape_with_halo)\n",
    "lap = np.empty_like(phi)\n",
    "\n",
    "lap_numpy(phi, lap)\n",
    "\n",
    "%timeit lap_numpy(phi, lap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 701 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def lap_cupy(phi, lap):\n",
    "    lap[1:-1, 1:-1] = (\n",
    "        - 4. * phi[1:-1, 1:-1]\n",
    "        +      phi[ :-2, 1:-1]\n",
    "        +      phi[  2:, 1:-1]\n",
    "        +      phi[1:-1,  :-2]\n",
    "        +      phi[1:-1,   2:]\n",
    "    )\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "    \n",
    "phi = cp.asarray(np.random.rand(*shape_with_halo))\n",
    "lap = cp.empty_like(phi)\n",
    "\n",
    "lap_cupy(phi, lap)\n",
    "\n",
    "%timeit lap_cupy(phi, lap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GT4Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 μs ± 438 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import gt4py.next as gtx\n",
    "import numpy as np\n",
    "\n",
    "#backend = None             # Embedded, native Python execution\n",
    "#backend = gtx.gtfn_cpu     # Translated to C code\n",
    "backend = gtx.gtfn_gpu     # Translated to GPU (CUDA or HIP) code\n",
    "\n",
    "I = gtx.Dimension(\"I\")\n",
    "J = gtx.Dimension(\"J\")\n",
    "K = gtx.Dimension(\"K\")\n",
    "\n",
    "field_domain = gtx.domain({\n",
    "    I: (-1, shape[0] + 1),\n",
    "    J: (-1, shape[1] + 1),\n",
    "    K: (-1, shape[2] + 1),\n",
    "})\n",
    "\n",
    "IJKField = gtx.Field[gtx.Dims[I, J, K], gtx.float64]\n",
    "\n",
    "@gtx.field_operator\n",
    "def lap_gt4py(in_field: IJKField) -> IJKField:\n",
    "    lap_field = (\n",
    "        -4.0 * in_field\n",
    "        + in_field(I - 1)\n",
    "        + in_field(I + 1)\n",
    "        + in_field(J - 1)\n",
    "        + in_field(J + 1)\n",
    "    )\n",
    "    return lap_field\n",
    "\n",
    "@gtx.program\n",
    "def lap_gt4py_program(in_field: IJKField, nx: gtx.int32, ny: gtx.int32, nz: gtx.int32,\n",
    "    out: IJKField) -> None:\n",
    "    lap_gt4py(in_field, out=out, domain={I: (0, nx), J: (0, ny), K: (0, nz)})\n",
    "\n",
    "phi = gtx.as_field(field_domain, np.random.rand(*field_domain.shape), allocator=backend)\n",
    "lap = gtx.zeros(field_domain, dtype=gtx.float64, allocator=backend)\n",
    "\n",
    "lap_gt4py_stencil = lap_gt4py_program.with_backend(backend)\n",
    "\n",
    "def run():\n",
    "    lap_gt4py_stencil(in_field=phi, nx=shape[0], ny=shape[1], nz=shape[2], out=lap)\n",
    "    cp.cuda.runtime.deviceSynchronize()\n",
    "\n",
    "run()\n",
    "\n",
    "%timeit run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC4WC_kernel",
   "language": "python",
   "name": "hpc4wc_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
